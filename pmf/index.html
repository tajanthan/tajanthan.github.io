<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>PMF</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">PMF</h1>
      <h2 class="project-tagline"><strong>Proximal Mean-field for Neural Network Quantization</strong></br>
      Thalaiyasingam Ajanthan, Puneet K. Dokania, Richard Hartley, and Philip H. S. Torr</h2>
      <a href="docs/pmf.pdf" class="btn">pdf</a>
      <!--<a href="docs/memf_poster.pdf" class="btn">poster</a>-->
      <!--<a href="https://github.com/oval-group/DenseCRF" class="btn">code</a>-->
    </section>

    <section class="main-content">
      

<h2 id="abstract">Abstract</h2>
<p>
Compressing large Neural Networks (NN) by quantizing the parameters, while maintaining the performance is highly desirable due to reduced memory and time complexity. In this work, we cast NN quantization as a discrete labelling problem and leverage results from the extensively studied MRF optimization literature. Specifically, we examine relaxations to the discrete labelling problem, leading to an efficient iterative optimization procedure that involves stochastic gradient descent followed by a projection. We prove that our simple projected gradient descent approach is, in fact, equivalent to a proximal version of the well-known mean-field method. These findings allow the decades old and theoretically grounded research on MRF optimization to be used to design better network quantization schemes. Our experiments on standard classification datasets (MNIST, CIFAR10/100, TinyImageNet) with convolutional and residual architectures evidence that our algorithm obtains fully-quantized networks with accuracies very close to the floating-point reference networks.
</p>
<h2 id="publication">Publication</h2>
<p>Proximal Mean-field for Neural Network Quantization.<br />
<strong>Thalaiyasingam Ajanthan</strong>, Puneet K. Dokania, Richard Hartley, and Philip H. S. Torr.<br />
Arxiv Preprint: arXiv:1812.04353, April 2019.</p>
<p>[<a href="docs/pmf.pdf" title="pdf">pdf</a>] 
<!--    [<a href="docs/lpdensecrf_supp.pdf" title="supp">supplementary</a>]-->
[<a href="https://arxiv.org/abs/1812.04353" title="arxiv">arxiv</a>]
<!--[<a href="https://github.com/oval-group/DenseCRF" title="code">code</a>] -->
</p>

      <footer class="site-footer">
          <span class="site-footer-owner">
            <a href="../index.html#research">
                User profile</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
