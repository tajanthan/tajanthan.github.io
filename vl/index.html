<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>VL</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="../assets/stylesheets/normalize.css" media="screen">
    <link rel="stylesheet" type="text/css" href="../assets/stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="../assets/stylesheets/github-light.css" media="screen">
	<link rel="shortcut icon" href="../images/dlt.png" />
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Vision and Language Alignment</h1>
	  <!--<h2 class="project-tagline">
      <strong>Yao Lu, Stephen Gould, and Thalaiyasingam Ajanthan</strong>
	  </h2>
	  <h2 class="project-tagline">
	  Australian National University</h2>-->
    </section>

    <section class="main-content">
      

<h2 id="abstract">Abstract</h2>
<div>
With the introduction of vision and language founcational models, language guidance shown to be powerful in many computer vision applications. However, aligning images and text is not straightforward due to the intrinsic differences in each modality. In this project, we develop new approaches to align vision and language modalities while preserving the modality-specific information wherever applicable.

</div>

<h2 id="publications">Publications</h2>

<div>
Contrastive Difference Alignment Between Vision and Language for Composed Image Retrieval.<br />
Y. Duan, S. Ramasinghe, A. Long, S. Gould, and <strong>T. Ajanthan</strong>.<br />
Preprint, 2024.<br/>
<!--[<a href="docs/bsnn.pdf" title="pdf">pdf</a>] 
[<a href="https://arxiv.org/abs/2006.12169" title="arxiv">arxiv</a>]
[<a href="docs/bsnn-talk.pdf" title="talk">talk</a>]
[<a href="" class="bibLink">bib</a>] 
<pre class="bibBlock" style="display: none;">
@article{lu_bsnn_nn23,
  author = {Lu, Yao and Gould, Stephen and Ajanthan, Thalaiyasingam},
  title = {Bidirectional Self-Normalizing Neural Networks},
  journal = {NN},
  year = {2023}
}</pre>-->
</div></br>

<div>
Accept the Modality Gap: An Exploration in the Hyperbolic Space.<br />
S. Ramasinghe, V. Shevchenko, G. Avraham, and <strong>T. Ajanthan</strong>.<br />
Computer Vision and Pattern Recognition (CVPR), June 2024. <font color="darkorange">(highlight)</font><br/>
[<a href="../vl/docs/atmg.pdf" title="pdf">pdf</a>] 
[<a href="https://github.com/samgregoost/atmg" title="code">code</a>]
[<a href="" class="bibLink">bib</a>]
<pre class="bibBlock" style="display: none;">
@article{ramasinghe_atmg_cvpr24,
  author = {Ramasinghe, Sameera, and Shevchenko, Violetta, and Avraham, Gil, and Ajanthan, Thalaiyasingam},
  title = {Accept the Modality Gap: An Exploration in the Hyperbolic Space},
  journal = {CVPR},
  year = {2024}
}</pre>
</div></br>

<div>
Modality-Aware Adaptation of Contrastive Language-Image Models.<br />
A. Long, <strong>T. Ajanthan</strong>, and A. van den Hengel.<br />
ICLR Workshop: Mathematical and Empirical Understanding of Foundation Models, May 2023.<br/>
[<a href="../vl/docs/mater.pdf" title="pdf">pdf</a>] 
[<a href="" class="bibLink">bib</a>]
<pre class="bibBlock" style="display: none;">
@article{long_mater_iclr23,
  author = {Long, Alexander, and Ajanthan, Thalaiyasingam, and van den Hengel, Anton},
  title = {Modality-Aware Adaptation of Contrastive Language-Image Models},
  journal = {ICLR Workshop: Mathematical and Empirical Understanding of Foundation Models},
  year = {2023}
}</pre>
</div>
														

      <footer class="site-footer">
          <span class="site-footer-owner">
            <a href="../index.html#research">
                User profile</a>.</span>
      </footer>

    </section>
	<script src="../assets/js/jquery.min.js"></script>
	<script src="../assets/js/bib.js" type="text/javascript"></script>
  
  </body>
</html>
