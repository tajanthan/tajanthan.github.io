<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>L2A</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">L2A</h1>
      <h2 class="project-tagline"><strong>Learning to Adapt for Stereo</strong></br>
      Alessio Tonioni, Oscar Rahnama*, Thomas Joy*, Luigi Di Stefano, Thalaiyasingam Ajanthan, and Philip H.S. Torr</h2>
      <a href="docs/l2a.pdf" class="btn">pdf</a>
      <!--<a href="docs/memf_poster.pdf" class="btn">poster</a>-->
      <a href="https://github.com/CVLAB-Unibo/Learning2AdaptForStereo" class="btn">code</a>
    </section>

    <section class="main-content">
      

<h2 id="abstract">Abstract</h2>
<p>
Real world applications of stereo depth estimation require models that are robust to dynamic variations in the environment. Even though deep learning based stereo methods are successful, they often fail to generalize to unseen variations in the environment, making them less suitable for practical applications such as autonomous driving. In this work, we introduce a “learning-to-adapt” framework that enables deep stereo methods to continuously adapt to new target domains in an unsupervised manner. Specifically, our approach incorporates the adaptation procedure into the learning objective to obtain a base set of parameters that are better suited for unsupervised online adaptation. To further improve the quality of the adaptation, we learn a confidence measure that effectively masks the errors introduced during the unsupervised adaptation. We evaluate our method on synthetic and real-world stereo datasets and our experiments evidence that learning-to-adapt is, indeed beneficial for online adaptation on vastly different domains.
</p>
<h2 id="publication">Publication</h2>
<p>Learning to Adapt for Stereo.<br />
Alessio Tonioni, Oscar Rahnama*, Thomas Joy*, Luigi Di Stefano, <strong>Thalaiyasingam Ajanthan</strong>, and Philip H.S. Torr.<br />IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2019.</p>
<p>[<a href="docs/l2a.pdf" title="pdf">pdf</a>] 
[<a href="docs/l2a-supp.pdf" title="supp">supplementary</a>]
[<a href="https://arxiv.org/abs/1904.02957" title="arxiv">arxiv</a>] 
<!--[<a href="docs/rwalk_poster.pdf" title="poster">poster</a>]-->
[<a href="https://github.com/CVLAB-Unibo/Learning2AdaptForStereo" title="code">code</a>]

      <footer class="site-footer">
          <p>* Equal contribution.</p>
          <span class="site-footer-owner">
            <a href="https://tajanthan.github.io/#research">
                User profile</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
